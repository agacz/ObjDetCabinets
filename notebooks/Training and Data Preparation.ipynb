{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following files from the source directory are needed:\n",
    "*   __src/preproc.py__ – functions used to preprocess the data\n",
    "*   __src/visualize.py__ – tools to visualize processed images\n",
    "*   __src/generate_tfrecord.py__ – a script to generate TF .record files from image data and XML annotations\n",
    "\n",
    "Assumed project structure:\n",
    "```\n",
    "main_project_dir/\n",
    "├─ README.md                               \n",
    "├─ data/                  \n",
    "│   ├─ train-valid-split\n",
    "│   │    ├─ synth_train/                   <- synthesized training set plus annotations\n",
    "│   │    ├─ synth_valid/                   <- synthesized validation set plus annotations\n",
    "│   │    ├─ train/                         <- preprocessed (in training notebook) training images with xml annotations\n",
    "│   │    ├─ valid/                         <- preprocessed (in training notebook) validation images with xml annotations\n",
    "│   │    ├─ train.record                   <- TF .record file containing the training data\n",
    "│   │    ├─ valid.record                   <- TF .record file containing the validation data\n",
    "│   │    └─ label_map.pbtxt                <- label map file that maps class IDs to class names\n",
    "│   └─ test-images-all                     <- test images used for evaluation\n",
    "├─ tf-models/                              \n",
    "│   ├─ pre-trained/                        <- pre-trained models downloaded from TF Object Detection Model Zoo\n",
    "│   └─ fine-tuned/                         <- fine-tuned models trained on the data in train-valid-split\n",
    "├─ notebooks/                              <- notebooks used for training, validation and evaluation\n",
    "└─ src/                                    <- modules used in the notebooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Paths common to entire workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "NOTEBOOK_DIR = Path(os.getcwd().replace(' ',''))\n",
    "MAIN_DIR1 = Path(os.path.abspath(\"..\").replace(' ',''))\n",
    "sys.path.insert(0, str(MAIN_DIR1))\n",
    "MAIN_DIR = MAIN_DIR1#/'CabinetsCV'\n",
    "\n",
    "DATA_DIR = MAIN_DIR/'data'\n",
    "#RAW_TEST_DATA_DIR = DATA_DIR/'test-annotated-images'\n",
    "TRAIN_VALID_DIR = DATA_DIR/'train-valid-split' # Processed (e.g. resized, augmented) training/validation data \n",
    "synth_train_data_dir = TRAIN_VALID_DIR/'synth_train' # RAW synthesized images, training\n",
    "synth_valid_data_dir = TRAIN_VALID_DIR/'synth_valid' # RAW synthesized images, validation\n",
    "\n",
    "# Models working directory\n",
    "MODELS_DIR = MAIN_DIR/'models'\n",
    "PRE_MODELS_DIR = MODELS_DIR/'pre-trained' # Pretrained models from TF model zoo\n",
    "FT_MODELS_DIR = MODELS_DIR/'fine-tuned' # Our fine-tuned models\n",
    "TF_DIR = MAIN_DIR/\"tf-models\"  # tensorflow models directory\n",
    "TF_DIR_OD = MAIN_DIR/\"tf-models/research\"\n",
    "\n",
    "# Directories for preprocessed annotated image data used for training/validation\n",
    "train_data_dir = TRAIN_VALID_DIR/'train'\n",
    "valid_data_dir = TRAIN_VALID_DIR/'valid'\n",
    "if not train_data_dir.exists():\n",
    "    train_data_dir.mkdir()\n",
    "if not valid_data_dir.exists():\n",
    "    valid_data_dir.mkdir()\n",
    "\n",
    "# Paths to TF .record files containing training and validation data (including annotations)\n",
    "train_tfrec_path = TRAIN_VALID_DIR/'train.record'\n",
    "valid_tfrec_path = TRAIN_VALID_DIR/'valid.record'\n",
    "\n",
    "# Path to the label map file that maps class IDs to class names\n",
    "label_map_path = TRAIN_VALID_DIR/'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install extra packages and update openCV headless\n",
    "!pip install seaborn imgaug -q\n",
    "!pip install opencv-python-headless --upgrade -q\n",
    "\n",
    "# install Object Detection API\n",
    "%cd $TF_DIR_OD\n",
    "!protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip -q install . \n",
    "%cd $MAIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "VERIFICATION_SCRIPT = os.path.join(TF_DIR, 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Object Detection API correct installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# TF object detection API utils\n",
    "from object_detection.utils import label_map_util \n",
    "from object_detection.utils import config_util \n",
    "\n",
    "# our src/ functions\n",
    "import src.preproc as src_pre\n",
    "import src.visualize as src_viz\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Image size variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target size of training/validation images after preprocessing (should be consistent with the model in use)\n",
    "IMAGE_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/update label map file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $label_map_path\n",
    "  item {\n",
    "    id: 1\n",
    "    name: 'AllenBradley'\n",
    "  }\n",
    "  item {\n",
    "    id: 2\n",
    "    name: 'AllenBradleyXM121'\n",
    "  }\n",
    "  item {\n",
    "    id: 3\n",
    "    name: 'Fanuc9030'\n",
    "  }\n",
    "  item {\n",
    "    id: 4\n",
    "    name: 'Ovation'\n",
    "  }\n",
    "  item {\n",
    "    id: 5\n",
    "    name: 'Siemens'\n",
    "  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(label_map_path)\n",
    "label_map_dict = label_map_util.get_label_map_dict(str(label_map_path))\n",
    "# Number of classes extracted from the label map\n",
    "num_classes = len(label_map_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data processing and augmentation\n",
    "If reusing tfrecords file, can skip to Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy synthetic data into synth_train and synth_valid folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear train/validation directories if they exist\n",
    "src_pre.clear_dir(train_data_dir)\n",
    "src_pre.clear_dir(valid_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "# double check all the files were copied correctly into the synth data directory\n",
    "file_dir = Path(synth_train_data_dir)\n",
    "\n",
    "filenames = os.listdir(os.path.join(file_dir))\n",
    "filenames = [os.path.join(file_dir, f) for f in filenames if (f.endswith('.jpg'))]\n",
    "print(len(filenames))\n",
    "for f in filenames:\n",
    "    jf = f\n",
    "    xf = f.replace('.jpg','.xml')\n",
    "    xf_path = Path(xf)\n",
    "    if not xf_path.is_file():\n",
    "        print(xf)\n",
    "\n",
    "filenames = os.listdir(os.path.join(file_dir))\n",
    "filenames = [os.path.join(file_dir, f) for f in filenames if (f.endswith('.xml'))]\n",
    "print(len(filenames))\n",
    "for f in filenames:\n",
    "    jf = f\n",
    "    xf = f.replace('.xml','.jpg')\n",
    "    xf_path = Path(xf)\n",
    "    if not xf_path.is_file():\n",
    "        print(xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize, apply augmentation to images and annotations in SYNTH_TRAIN_DATA_DIR \n",
    "# and place the processed data in train_data_dir.\n",
    "src_pre.copy_augment_data(\n",
    "    synth_train_data_dir, train_data_dir,\n",
    "    augment_mult = 10, # how many extra images to produce\n",
    "    target_max_size = IMAGE_SIZE,\n",
    "    pad2square = True,\n",
    "    rand_augment = True,\n",
    "    rand_aug_mag = 1.8, # magnitude of augmentation\n",
    "    rand_aug_num =  2., # number of augmentations per image\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images to the validation data folder WITHOUT augmentation\n",
    "# Resize the images in-place. Augmentation should be disabled for validation data.\n",
    "src_pre.copy_augment_data(synth_valid_data_dir, valid_data_dir, \n",
    "                          target_max_size=IMAGE_SIZE,\n",
    "                          pad2square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "# Resize, apply augmentation to images and annotations in SYNTH_VALID_DATA_DIR \n",
    "# and place the processed data in train_data_dir.\n",
    "src_pre.copy_augment_data(\n",
    "    synth_valid_data_dir, valid_data_dir,\n",
    "    augment_mult = 5,\n",
    "    target_max_size = IMAGE_SIZE,\n",
    "    pad2square = True,\n",
    "    rand_augment = True,\n",
    "    rand_aug_mag = 1,\n",
    "    rand_aug_num = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TFRecords files\n",
    "%cd $MAIN_DIR\n",
    "!python src/generate_tfrecord.py -x $train_data_dir -l $label_map_path -o $train_tfrec_path\n",
    "!python src/generate_tfrecord.py -x $valid_data_dir -l $label_map_path -o $valid_tfrec_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a pre-trained model\n",
    "PRE_MODEL_NAME = 'efficient_det_1024'\n",
    "\n",
    "# Set the name of our fine-tuned model\n",
    "MY_MODEL_NAME = 'efficient_det_all_demo' #change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL: set up new model\n",
    "#import tarfile\n",
    "#ZIP_LOC = PRE_MODELS_DIR/'faster_rcnn.tar.gz'\n",
    "#with tarfile.open(ZIP_LOC, \"r:gz\") as tar:\n",
    "#    tar.extractall(PRE_MODELS_DIR)\n",
    "#os.remove(ZIP_LOC)\n",
    "## change permissions\n",
    "#faster_rcnn = PRE_MODELS_DIR/'faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "#os.chmod(faster_rcnn, 775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set directories and paths for the model\n",
    "# Our model directory\n",
    "my_model_dir = FT_MODELS_DIR / MY_MODEL_NAME\n",
    "if not my_model_dir.exists(): my_model_dir.mkdir()\n",
    "\n",
    "# Make a folder for the exported model\n",
    "my_export_dir = my_model_dir/'exported'\n",
    "if not my_export_dir.exists():\n",
    "    my_export_dir.mkdir()\n",
    "\n",
    "# Path to the initial fine tune checkpoint (from the pre-trained model)\n",
    "ft_ckpt_dir = my_model_dir / 'fine_tune_checkpoint'\n",
    "if not ft_ckpt_dir.exists(): ft_ckpt_dir.mkdir()\n",
    "ft_ckpt_path = ft_ckpt_dir / 'ckpt-0'\n",
    "\n",
    "# Path to the model configuration file\n",
    "config_path = my_model_dir / 'pipeline.config'\n",
    "\n",
    "# Copy checkpint file into our model\n",
    "for ckpt_file in glob.glob(str(PRE_MODELS_DIR/PRE_MODEL_NAME/'checkpoint/ckpt-0.*')):\n",
    "    shutil.copyfile(ckpt_file, ft_ckpt_dir / Path(ckpt_file).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size (reduce if out of GPU memory)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy and modify the pipeline.config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the config file to our model directory\n",
    "#shutil.copy(PRE_MODELS_DIR/PRE_MODEL_NAME/\"pipeline.config\", config_path)\n",
    "# or copy the existing pre-configured pipeline.config\n",
    "shutil.copy(FT_MODELS_DIR/\"pipeline.config\", config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config file (or do edits manually)\n",
    "config = config_util.get_configs_from_pipeline_file(config_path)\n",
    "\n",
    "# update path to fine-tune checkpoint\n",
    "config['train_config'].fine_tune_checkpoint = str(ft_ckpt_path)\n",
    "config['train_input_config'].label_map_path = str(label_map_path)\n",
    "config['train_input_config'].tf_record_input_reader.input_path[0] = str(train_tfrec_path)\n",
    "config['eval_input_config'].label_map_path = str(label_map_path)\n",
    "config['eval_input_config'].tf_record_input_reader.input_path[0] = str(valid_tfrec_path)\n",
    "\n",
    "# update batch size\n",
    "config['train_config'].batch_size = BATCH_SIZE\n",
    "config['eval_config'].batch_size = BATCH_SIZE\n",
    "if BATCH_SIZE<=4:\n",
    "  # improves training for small batch sizes\n",
    "  config['model'].ssd.freeze_batchnorm = True\n",
    "\n",
    "# update num classes\n",
    "config['model'].ssd.num_classes = num_classes\n",
    "    \n",
    "# reduce learning rate for smaller batch sizes\n",
    "default_lr = config['train_config'].optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base\n",
    "default_warmup_lr = config['train_config'].optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate\n",
    "f = np.sqrt(BATCH_SIZE/32)\n",
    "config['train_config'].optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base = f * default_lr\n",
    "config['train_config'].optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate = f * default_warmup_lr\n",
    "\n",
    "# tune the aspect_ratios\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.pop(0)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.pop(0)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.pop(0)\n",
    "\n",
    "#ab only: 1.5, 1.8, 2.0, 2.25, 2.5\n",
    "#config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(1.5)\n",
    "#config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(1.8)\n",
    "#config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(2.0)\n",
    "#config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(2.25)\n",
    "#config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(2.5)\n",
    "\n",
    "#all controllers:\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(0.3)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(0.6)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(1.5)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(1.75)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(2.0)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(2.25)\n",
    "config['model'].ssd.anchor_generator.multiscale_anchor_generator.aspect_ratios.append(2.5)\n",
    "\n",
    "# save the updated configuration\n",
    "config_proto = config_util.create_pipeline_proto_from_configs(config)\n",
    "config_util.save_pipeline_config(config_proto, my_model_dir)\n",
    "\n",
    "os.chmod(config_path, 775)  # save persmission to allow editing in winSCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "# to train on less GPU's (for example to get the evaluatio script to run on a GPU):\n",
    "#import tensorflow as tf\n",
    "#tf.config.list_physical_devices('GPU')\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint every n steps:\n",
    "check_num = 500\n",
    "tot_steps = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a shell script for training, and execute it from a terminal (INSIDE the notebooks directory)\n",
    "%cd $NOTEBOOK_DIR\n",
    "training_script = f\"\"\"python {TF_DIR}/research/object_detection/model_main_tf2.py --model_dir={my_model_dir} --pipeline_config_path={config_path} --num_train_steps={tot_steps} --checkpoint_every_n={check_num}\"\"\"\n",
    "with open('training_launch.sh', 'w') as fp:\n",
    "    fp.write(training_script)\n",
    "    \n",
    "os.chmod(\"training_launch.sh\", 755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPTIONAL\n",
    "## or run training from the notebook:\n",
    "#%cd $NOTEBOOK_DIR\n",
    "#!python {TF_DIR}/research/object_detection/model_main_tf2.py --model_dir={my_model_dir} --pipeline_config_path={config_path} --checkpoint_every_n={check_num}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run validation in parallel using the Validation notebook. Wait for the cuDNN to get loaded (takes about 10-15 minutes); launch tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {TF_DIR/'research/object_detection'}\n",
    "!python exporter_main_v2.py \\\n",
    "--input_type image_tensor \\\n",
    "--pipeline_config_path $config_path \\\n",
    "--trained_checkpoint_dir $my_model_dir \\\n",
    "--output_directory $my_export_dir\n",
    "%cd {NOTEBOOK_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can modify which checkpoint to use\n",
    "This is done by opening {my_model_dir}/checkpoint file and modifying model_checkpoint_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change permissions of checkpoint file so it can be edited\n",
    "checkpoint_file = os.path.join(my_model_dir,'checkpoint')\n",
    "os.chmod(checkpoint_file, 775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a folder for the (extra) exported model with different checkpoint, then rerun the Save Model\n",
    "my_export_dir = my_model_dir/'exported-2'\n",
    "if not my_export_dir.exists():\n",
    "    my_export_dir.mkdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
