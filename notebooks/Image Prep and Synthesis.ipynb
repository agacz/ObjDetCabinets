{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image synthesis; preprocessing, directory creation, fixing of xml files, copying of files to correct directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, sys, shutil, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDirectories(file_dir, input_objects, input_background):\n",
    "    # prepare the directory for synthesis, copy over chosen files and remove output directory\n",
    "    \n",
    "    selected_objects = os.path.join(file_dir, input_objects)\n",
    "    selected_backgrounds = os.path.join(file_dir, input_background)\n",
    "\n",
    "    objects_dir = os.path.join(file_dir, 'data_dir', 'objects_dir')\n",
    "    bg_dir = os.path.join(file_dir, 'data_dir', 'backgrounds')\n",
    "\n",
    "    if os.path.exists(objects_dir):\n",
    "        shutil.rmtree(objects_dir)\n",
    "    if os.path.exists(bg_dir):\n",
    "        shutil.rmtree(bg_dir)\n",
    "\n",
    "    shutil.copytree(selected_objects, objects_dir)\n",
    "    shutil.copytree(selected_backgrounds, bg_dir)\n",
    "\n",
    "    output_dir = os.path.join(file_dir, 'output_dir')\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        \n",
    "def convert_copy_xml(data_dir):\n",
    "    #run from inside the EPRI generate synth dataset directory\n",
    "    #convert xml files from the output_dir of generate synthetic data and copy to data_dir\n",
    "\n",
    "    # clear existing directory; add if it doesn't exist\n",
    "    if os.path.exists(data_dir):\n",
    "        shutil.rmtree(data_dir)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    \n",
    "    file_dir = os.path.join('output_dir','train.txt')\n",
    "    file = open(file_dir, 'r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        img_path = line.split()[0] # read the image path from the train.txt file (output of the synthesis)\n",
    "        xml_path = line.split()[1] # read the xml path\n",
    "        img_name = img_path.rsplit('/')[-1] # name of the jpg image without directories\n",
    "        \n",
    "        new_xml_file = os.path.join(data_dir,img_name.rsplit('.')[0]+str('.xml')) \n",
    "                #new xml file name based on jpg image name\n",
    "        new_img_file = os.path.join(data_dir,img_name) #new directory for jpg image\n",
    "        \n",
    "        #copy renamed xml files and the jpg's\n",
    "        shutil.copyfile(xml_path, new_xml_file)\n",
    "        shutil.copyfile(img_path, new_img_file)\n",
    "\n",
    "        #open the xml file and change the file_name to img_name\n",
    "        with open(new_xml_file) as xf:\n",
    "            xml_data = xf.read()\n",
    "            dict_data = xmltodict.parse(xml_data)\n",
    "            newText=xml_data.replace(dict_data['annotation']['filename'], img_name)\n",
    "\n",
    "        with open(new_xml_file, \"w\") as f:\n",
    "            f.write(newText)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set all the directories and chosen target images, backgrounds, and output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = Path('/Users/Aga/Desktop/EPRI_generate_synth_dataset')\n",
    "\n",
    "#IMAGE_DIR = 'all_valid'\n",
    "#TARGET_DIR = 'synth_valid'\n",
    "\n",
    "IMAGE_DIR = 'all_train'\n",
    "TARGET_DIR = 'synth_train'\n",
    "\n",
    "BG_DIR = 'backgrounds_1024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old directory files and opy over files from IMAGE_DIR to input directory of dataset generator\n",
    "prepareDirectories(file_dir, IMAGE_DIR, BG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize chosen images (i.e. train or valid, which backgrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/Users/Aga/Desktop/EPRI_generate_synth_dataset'\n",
    "!python dataset_generator.py --n_image 350 --dontocclude \\\n",
    " --add_distractors --separate_box_mask data_dir/objects_dir output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy annotation files and rename them, including inside the xml files, for all blended synth image versions, copy files to target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_copy_xml(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove none images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $TARGET_DIR\n",
    "noneImg = (glob.glob('*_none.jpg'))\n",
    "noneXml = (glob.glob('*_none.xml'))\n",
    "os.mkdir('none')\n",
    "for nn in noneImg:\n",
    "    shutil.move(nn,'none')\n",
    "for n in noneXml:\n",
    "    shutil.move(n,'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate bounding box sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "def xml_to_boxes(path, rescale_width=None, rescale_height=None):\n",
    "    \"\"\"Extracts bounding-box widths and heights from ground-truth dataset.\n",
    "\n",
    "    Args:\n",
    "    path : Path to .xml annotation files for your dataset.\n",
    "    rescale_width : Scaling factor to rescale width of bounding box.\n",
    "    rescale_height : Scaling factor to rescale height of bounding box.\n",
    "\n",
    "    Returns:\n",
    "    bboxes : A numpy array with pairs of box dimensions as [width, height].\n",
    "    \"\"\"\n",
    "    xml_list = []\n",
    "    img_size = []\n",
    "    bad_files = []\n",
    "    filenames = os.listdir(os.path.join(path))\n",
    "    filenames = [os.path.join(path, f) for f in filenames if (f.endswith('.xml'))]\n",
    "    for xml_file in filenames:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('size'):\n",
    "            ww = int(member.find('width').text)\n",
    "            hh = int(member.find('height').text)\n",
    "        for member in root.findall('object'):\n",
    "            bndbox = member.find('bndbox')\n",
    "            bbox_width = int(bndbox.find('xmax').text) - int(bndbox.find('xmin').text)\n",
    "            bbox_height = int(bndbox.find('ymax').text) - int(bndbox.find('ymin').text)\n",
    "            if rescale_width and rescale_height:\n",
    "                size = root.find('size')\n",
    "                bbox_width = bbox_width * (rescale_width / int(size.find('width').text))\n",
    "                bbox_height = bbox_height * (rescale_height / int(size.find('height').text))\n",
    "            xml_list.append([bbox_width, bbox_height])\n",
    "            img_size.append([ww,hh])\n",
    "            if ((bbox_width<34) or (bbox_height<34)):\n",
    "                bad_files.append(xml_file)\n",
    "    bboxes = np.array(xml_list)\n",
    "    return bboxes, img_size, bad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = Path('/Users/Aga/Desktop/EPRI_generate_synth_dataset/synth_valid/')\n",
    "boxArr, imgSize, bf_xml = xml_to_boxes(file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find x and y width of bounding boxes for anchor box tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xw = [boxArr[n][0] for n in range(len(boxArr))]\n",
    "yw = [boxArr[n][1] for n in range(len(boxArr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_s = sorted(yw,reverse=False)\n",
    "yw_s[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [boxArr[n][0]/boxArr[n][1] for n in range(len(boxArr))]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "ax.hist(ratio, bins = 50)\n",
    "ax.set_title('X width / Y width, synth training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove files with too small bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the unique file numbers for bad files with small bounxing boxes (<34)\n",
    "bf_unique = [f for f in bf_xml if (f.endswith('.xml'))]\n",
    "print(len(set(bf_unique)), ' bad files in dir: ', str(file_dir))\n",
    "\n",
    "bf_jpg = [b.replace('.xml','.jpg') for b in bf_xml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_xml.sort()\n",
    "bf_jpg.sort()\n",
    "for i,f in enumerate(bf_xml):\n",
    "    os.remove(f)\n",
    "    os.remove(bf_jpg[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if all jpg's have xml files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = Path('/Users/Aga/Desktop/EPRI_generate_synth_dataset/synth_train_valid_v5/synth_train/')\n",
    "\n",
    "filenames = os.listdir(os.path.join(file_dir))\n",
    "filenames = [os.path.join(file_dir, f) for f in filenames if (f.endswith('.jpg'))]\n",
    "print(len(filenames))\n",
    "for f in filenames:\n",
    "    jf = f\n",
    "    xf = f.replace('.jpg','.xml')\n",
    "    xf_path = Path(xf)\n",
    "    if not xf_path.is_file():\n",
    "        print(xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(os.path.join(file_dir))\n",
    "filenames = [os.path.join(file_dir, f) for f in filenames if (f.endswith('.xml'))]\n",
    "print(len(filenames))\n",
    "for f in filenames:\n",
    "    jf = f\n",
    "    xf = f.replace('.xml','.jpg')\n",
    "    xf_path = Path(xf)\n",
    "    if not xf_path.is_file():\n",
    "        print(xf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change names of extra synthetic images, also inside the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_filename_XML(new_xml_file, img_name):\n",
    "    #open the xml file and change the file_name to img_name\n",
    "    with open(new_xml_file) as xf:\n",
    "        xml_data = xf.read()\n",
    "        dict_data = xmltodict.parse(xml_data)\n",
    "        newText = xml_data.replace(dict_data['annotation']['filename'], img_name)\n",
    "    with open(new_xml_file, \"w\") as f:\n",
    "        f.write(newText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/Users/Aga/Desktop/EPRI_generate_synth_dataset/synth_valid'\n",
    "noneImg = (glob.glob('*.jpg'))\n",
    "for im in noneImg:\n",
    "    newName = im.replace('.jpg','_extra.jpg')\n",
    "    os.rename(im,newName)\n",
    "    xml_file = im.replace('.jpg','.xml')\n",
    "    new_xml_file = xml_file.replace('.xml','_extra.xml')\n",
    "    change_filename_XML(xml_file, newName)\n",
    "    os.rename(xml_file,new_xml_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
